{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SAuGl2KP5tA"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMqyj0FZScy0"
      },
      "source": [
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxyoIeOFSd7B"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\r\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\r\n",
        "\r\n",
        "# Fetching some keras files\r\n",
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\r\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\r\n",
        "\r\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\r\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\r\n",
        "\r\n",
        "train_y = train.pop('Species')\r\n",
        "test_y = test.pop('Species')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHbLuTSTSmXX"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VsJxK2vTmzG"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XCkOLGsTu-A"
      },
      "source": [
        "Input Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkGn8BVLTunt"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\r\n",
        "    # Convert the inputs to a tf.data.Dataset\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n",
        "\r\n",
        "    # Shuffle and repeat if you are in training mode.\r\n",
        "    if training:\r\n",
        "        dataset = dataset.shuffle(1000).repeat()\r\n",
        "    \r\n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81tIVWvOT9E1"
      },
      "source": [
        "Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni8-EGO2T-UF"
      },
      "source": [
        "# Feature columns describe how to use the input.\r\n",
        "my_feature_columns = []\r\n",
        "for key in train.keys():\r\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n",
        "# print(my_feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4X6InglUrqK"
      },
      "source": [
        "Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL_Z0AEOUtPz"
      },
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\r\n",
        "classifier = tf.estimator.DNNClassifier(\r\n",
        "    feature_columns=my_feature_columns,\r\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\r\n",
        "    hidden_units=[30, 10],\r\n",
        "    # The model must choose between 3 classes.\r\n",
        "    n_classes=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01v70pZHVRh1"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOFpbo-VSdl"
      },
      "source": [
        "classifier.train(\r\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\r\n",
        "    steps=5000)\r\n",
        "# We include a lambda to avoid creating an inner function previously"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4ZV5l7tVgxu"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USmwyqEqVh3n"
      },
      "source": [
        "eval_result = classifier.evaluate(\r\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\r\n",
        "\r\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na1QGrvwVk6O"
      },
      "source": [
        "Predictions : Run this, it's interactive!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKoQW0y1Vl65"
      },
      "source": [
        "def input_fn(features, batch_size=256):\r\n",
        "    # Convert the inputs to a Dataset without labels.\r\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\r\n",
        "\r\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\r\n",
        "predict = {}\r\n",
        "\r\n",
        "print(\"Please type numeric values as prompted.\")\r\n",
        "for feature in features:\r\n",
        "  valid = True\r\n",
        "  while valid: \r\n",
        "    val = input(feature + \": \")\r\n",
        "    if not val.isdigit(): valid = False\r\n",
        "\r\n",
        "  predict[feature] = [float(val)]\r\n",
        "\r\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\r\n",
        "for pred_dict in predictions:\r\n",
        "    class_id = pred_dict['class_ids'][0]\r\n",
        "    probability = pred_dict['probabilities'][class_id]\r\n",
        "\r\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\r\n",
        "        SPECIES[class_id], 100 * probability))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}